import sys
import os
import argparse
import snptools as snp
import textwrap


def scrape_snpeff_html_to_txt(path_to_files, file_extension, path_to_output_files):
    files = snp.access_folder_contents(path_to_files,file_extension)
    for f in files:
        if 'Enterococcus_faecalis' in f: # Escherichia_coli
            print(f)

def test_1():
    print('test1 function')

def test_2():
    print('test2 function')

def read_params():
    FUNCTION_MAP = {'scrape_snpeff_html_to_txt' : scrape_snpeff_html_to_txt,
                    'test_1' : test_1,
                    'test_2' : test_2 }

    p = argparse.ArgumentParser(
            formatter_class=argparse.RawDescriptionHelpFormatter,
            description=textwrap.dedent('''    -------------------------------------------------------------------
    
    Microbial SNP pipeline using bcftools and SNPEff
    Visit documentation for examples: github/flannsmith/snp-calling

    -------------------------------------------------------------------'''))

    p.add_argument('command', choices=FUNCTION_MAP.keys())

    p.add_argument('--path_to_html_files', type=str, help='Path to html files for scraping.')
    p.add_argument('--file_extension', type=str, help='File extension of files e.g. \'.html\'')
    p.add_argument('--path_to_output_files', type=str, default=os.getcwd(), help='Path to output scraped files.')
    p.add_argument('--path_to_txt_files', type=str, help='Path to txt files for scraping. These are the intermediate files generated by running --path_to_html_files.')

    args = p.parse_args()
    func = FUNCTION_MAP[args.command]
    func()


# def read_params(args):
#     p = argparse.ArgumentParser(
#         formatter_class=argparse.RawDescriptionHelpFormatter,
#         description=textwrap.dedent('''Microbial SNP pipeline using bcftools and SNPEff
#                                     ----------------------------------------------------
#                                     Visit documentation for examples: github/flannsmith/snp-calling''')
#     p.add_argument('--path_to_html_files', type=str, help='Path to html files for scraping.')
#     p.add_argument('--file_extension', type=str, help='File extension of files e.g. \'.html\'')
#     p.add_argument('--path_to_output_files', type=str, default=os.getcwd(), help='Path to output scraped files.')
#     p.add_argument('--path_to_txt_files', type=str, help='Path to txt files for scraping. These are the intermediate files generated by running --path_to_html_files.')



def main():
    read_params()


if __name__ == '__main__':
    main()


